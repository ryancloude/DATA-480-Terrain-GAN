{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36dAOf4x1Gd5",
        "outputId": "1d48bf7d-aa22-443e-c96a-7c057c336d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.2 kt-legacy-1.0.4\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "!pip install keras-tuner\n",
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "#from tensorflow.keras import mixed_precision\n",
        "import keras_tuner as kt\n",
        "#policy = mixed_precision.Policy('mixed_float16')\n",
        "#mixed_precision.set_global_policy(policy)\n",
        "keras.utils.set_random_seed(9)\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9xPCCfc1WNw"
      },
      "outputs": [],
      "source": [
        "injury_history = pd.read_csv('/content/drive/MyDrive/data_490/injury_data/injury_history')\n",
        "bio_data = pd.read_csv('/content/drive/MyDrive/data_490/processed_data/bio_data.csv')\n",
        "ts_data = pd.read_pickle('/content/drive/MyDrive/data_490/processed_data/thirty_day_timestep_df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRYrSMxaRFTc"
      },
      "outputs": [],
      "source": [
        "bio_data.player_age = bio_data['player_age'].str.split(' ').str[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh1sdJDT4_-_"
      },
      "outputs": [],
      "source": [
        "indexes = np.random.permutation(len(ts_data))\n",
        "train_size = int(len(indexes)*.8)\n",
        "valid_size = int(train_size*.2)\n",
        "train_indexes = indexes[valid_size:train_size]\n",
        "np.savetxt(\"/content/drive/MyDrive/data_490/processed_data/train_indexes.csv\", train_indexes, delimiter=\",\")\n",
        "valid_indexes = indexes[:valid_size]\n",
        "np.savetxt(\"/content/drive/MyDrive/data_490/processed_data/valid_indexes.csv\", valid_indexes, delimiter=\",\")\n",
        "test_indexes = indexes[train_size:]\n",
        "np.savetxt(\"/content/drive/MyDrive/data_490/processed_data/test_indexes.csv\", test_indexes, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Cf9O5wJSux"
      },
      "outputs": [],
      "source": [
        "bio_data = bio_data.fillna(-1)\n",
        "injury_history = injury_history.fillna(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmtR3SYv57Kg"
      },
      "outputs": [],
      "source": [
        "ts_train = np.stack(ts_data.loc[train_indexes, 'time_series'].values).astype(np.float16)[:,:,:-1]\n",
        "ts_valid = np.stack(ts_data.loc[valid_indexes, 'time_series'].values).astype(np.float16)[:,:,:-1]\n",
        "ts_test = np.stack(ts_data.loc[test_indexes, 'time_series'].values).astype(np.float16)[:,:,:-1]\n",
        "bio_train = bio_data.iloc[train_indexes, 2:].astype(np.float16)\n",
        "bio_valid = bio_data.iloc[valid_indexes, 2:].astype(np.float16)\n",
        "bio_test = bio_data.iloc[test_indexes, 2:].astype(np.float16)\n",
        "injury_train = injury_history.iloc[train_indexes, 2:].astype(np.float16)\n",
        "injury_valid = injury_history.iloc[valid_indexes, 2:].astype(np.float16)\n",
        "injury_test = injury_history.iloc[test_indexes, 2:].astype(np.float16)\n",
        "train_target =  ts_data.loc[train_indexes, 'injured'].astype(np.float16)\n",
        "valid_target =  ts_data.loc[valid_indexes, 'injured'].astype(np.float16)\n",
        "test_target = ts_data.loc[test_indexes, 'injured'].astype(np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hRm3p_4oERM"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, dropout=0, time_steps=30, features=85):\n",
        "        super().__init__()\n",
        "        self.dropout = layers.Dropout(dropout)\n",
        "        p = np.zeros(np.shape((1, time_steps, features)))\n",
        "        columns = np.arange(features)\n",
        "        rows = np.arange(time_steps)\n",
        "        p = rows.reshape(-1,1)/1000**(columns*2/features)\n",
        "        p[:, 0::2] = np.sin(p[:,0::2])\n",
        "        p[:, 1::2] = np.cos(p[:, 1::2])\n",
        "        self.p = p\n",
        "\n",
        "    def call(self, x, **kwargs):\n",
        "        x = x + self.p\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znvTGaxs-SZR"
      },
      "outputs": [],
      "source": [
        "from re import X\n",
        "def transformer_encoder(inputs, head_size, num_heads, conv_filters, kernel_size, dropout=0):\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=conv_filters, kernel_size=kernel_size, activation=\"relu\", padding='same')(x)\n",
        "    X = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8XU07y3-TKA"
      },
      "outputs": [],
      "source": [
        "def build_mixed_model(\n",
        "    ts_input_shape,\n",
        "    injury_input_shape,\n",
        "    bio_input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=8,\n",
        "    conv_filters=64,\n",
        "    kernel_size=3,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=128,\n",
        "    mlp_layers=2,\n",
        "    encoder_dropout=0,\n",
        "    mlp_dropout=0,\n",
        "    pe_dropout=0,\n",
        "    embedding_dropout=0,\n",
        "    pe=True,\n",
        "    embedding=True,\n",
        "):\n",
        "    ts_input = keras.Input(shape=ts_input_shape)\n",
        "    x = ts_input\n",
        "    x = keras.layers.Normalization(axis=1)(x)\n",
        "    \n",
        "    #Embedding\n",
        "    if embedding:\n",
        "      x = layers.Flatten(input_shape=ts_input_shape)(x)\n",
        "      x = layers.Dense(ts_input_shape[-1]*ts_input_shape[-2], activation='tanh')(x)\n",
        "      x = layers.Dropout(embedding_dropout)(x)\n",
        "      x = layers.Reshape(ts_input_shape)(x)\n",
        "\n",
        "    #Positional Encoding\n",
        "    if pe:\n",
        "      x = PositionalEncoding()(x)\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, conv_filters, kernel_size, encoder_dropout)\n",
        "\n",
        "\n",
        "    bio_input = keras.Input(shape=bio_input_shape)\n",
        "    bio = layers.experimental.preprocessing.Normalization()(bio_input)\n",
        "\n",
        "    injury_input = keras.Input(shape=injury_input_shape) \n",
        "    injury = layers.experimental.preprocessing.Normalization()(injury_input)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    x = tf.keras.layers.Concatenate()([x, injury, bio])\n",
        "\n",
        "    for i in range(mlp_layers):\n",
        "        x = layers.Dense(mlp_units, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    inputs = [ts_input, injury_input, bio_input]\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbITDFZlnxfv"
      },
      "outputs": [],
      "source": [
        "ts_shape = np.shape(ts_train)[1:]\n",
        "injury_shape = np.shape(injury_train)[1:]\n",
        "bio_shape = np.shape(bio_train)[1:]\n",
        "\n",
        "model = build_mixed_model(\n",
        "    ts_shape,\n",
        "    injury_shape,\n",
        "    bio_shape,\n",
        "    head_size=256,\n",
        "    num_heads=32,\n",
        "    conv_filters=32,\n",
        "    kernel_size=3,\n",
        "    num_transformer_blocks=5,\n",
        "    mlp_units=128,\n",
        "    mlp_layers=4,\n",
        "    encoder_dropout=.28,\n",
        "    mlp_dropout=.15,\n",
        "    pe_dropout=.25,\n",
        "    embedding_dropout=.07,\n",
        "    pe=True,\n",
        "    embedding=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=9e-5)\n",
        "opt = tfa.optimizers.SWA(opt, start_averaging=20, average_period=1)\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=opt,\n",
        "    metrics=[keras.metrics.AUC()],\n",
        "    steps_per_execution=64,\n",
        "    jit_compile=True\n",
        ")"
      ],
      "metadata": {
        "id": "cKecoJUlXsz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr, warmup_epochs=20, decay_epochs=100, initial_lr=1e-10, base_lr=1e-4, min_lr=1e-8):\n",
        "    if epoch <= warmup_epochs:\n",
        "        pct = epoch / warmup_epochs\n",
        "        return ((base_lr - initial_lr) * pct) + initial_lr\n",
        "    if epoch > warmup_epochs and epoch < warmup_epochs+decay_epochs:\n",
        "        pct = 1 - ((epoch - warmup_epochs) / decay_epochs)\n",
        "        return ((base_lr - min_lr) * pct) + min_lr\n",
        "\n",
        "    return min_lr"
      ],
      "metadata": {
        "id": "kVSWneU0ozeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EmagkelsU4e"
      },
      "outputs": [],
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, monitor='val_auc', mode='max', restore_best_weights=False),\n",
        "             tf.keras.callbacks.LearningRateScheduler(scheduler)]\n",
        "\n",
        "history = model.fit([ts_train, injury_train, bio_train],\n",
        "            train_target,\n",
        "           validation_data=[[ts_valid, injury_valid, bio_valid], valid_target],\n",
        "           epochs=500, callbacks=callbacks,\n",
        "           batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/data_490/final_model')"
      ],
      "metadata": {
        "id": "WCmIY6Xu-HKG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Final Mixed Model Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QPGZA1Rkbz8QSS2U3OCKltYEXAfqTrvM",
      "authorship_tag": "ABX9TyMDYmJTCVl0djZ2TNq1MiPB"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}