{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Gmt_iC3qKcdj"
   },
   "outputs": [],
   "source": [
    "#Paths for files\n",
    "path_for_joined_geotiff_df = '' \n",
    "path_for_1km_by_1km_folder = ''\n",
    "path_for_folder_to_save_models = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajdaWFE9cEjs",
    "outputId": "921e37f3-e74d-468c-f377-3cc85a862538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from google.colab import drive\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from skimage.transform import resize\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JvIJjN9K-kUo"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_for_joined_geotiff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oeIV-lo1WhZX"
   },
   "outputs": [],
   "source": [
    "#These Rows (from yoesmetie) had random points with elevation in the billions, so I just exluded them\n",
    "outliers = [964, 970, 975, 976, 977, 982, 983, 984, 985, 992, 993, 994, 995]\n",
    "df = df[~df.index.isin(outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cxf8aYrFdTaw"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps_per_epoch = int(np.ceil(len(df)/batch_size))\n",
    "num_channels = 1\n",
    "num_classes = df.BIOME_NAME.nunique()\n",
    "image_size = 1000\n",
    "latent_dim = ((image_size*image_size)*num_classes)-num_classes\n",
    "generator_input = latent_dim + num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5ou0X5TxsXGP"
   },
   "outputs": [],
   "source": [
    "#Gets file name from the df and reads raster data from 1km_by_1km file\n",
    "file_head = path_for_1km_by_1km_folder\n",
    "dataset = []\n",
    "for index, row in df.iterrows():\n",
    "  path =  file_head + '/' +str(row.file_name)\n",
    "  ds = gdal.Open(path)\n",
    "  ds = np.array(ds.GetRasterBand(1).ReadAsArray())\n",
    "  ds[ds < 0] = 0\n",
    "  #Some tiles are .5 meter resolution, size 2000*2000, and some are 2 meter resolution, size 500*500.\n",
    "  if np.shape(ds) != (image_size, image_size):\n",
    "    #resizes all tiles to 1000*1000\n",
    "    ds = resize(ds, (image_size, image_size))\n",
    "  dataset.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LohWj4sDdLlE"
   },
   "outputs": [],
   "source": [
    "dataset = np.asarray(dataset)\n",
    "#Used to normalize images\n",
    "highest_point = np.max(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2x-1AcJubTOH"
   },
   "outputs": [],
   "source": [
    "#Adds channel to data\n",
    "dataset = np.expand_dims(dataset, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BDhRS30dZwjM"
   },
   "outputs": [],
   "source": [
    "#Class Labels\n",
    "labels =  pd.factorize(df.BIOME_NAME)\n",
    "all_labels = keras.utils.to_categorical(labels[0], len(df.BIOME_NAME.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RjLNhoEcbWjJ"
   },
   "outputs": [],
   "source": [
    "#Creates tesnor of raster data with class labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((dataset, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=len(dataset)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "luU_U67rdkTs"
   },
   "outputs": [],
   "source": [
    "discriminator_in_channels = num_channels + num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kgfaqFXHIJiw"
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "  discriminator = keras.Sequential(\n",
    "      [\n",
    "          keras.layers.InputLayer((image_size, image_size, discriminator_in_channels)),\n",
    "          #normalize images between -1 and 1\n",
    "          tf.keras.layers.Rescaling(1./highest_point, offset=-1),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\" \n",
    "                        , activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.Conv2D(128, (4, 4), strides=(2, 2), padding=\"same\" \n",
    "                        , activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.Conv2D(256, (4, 4), strides=(2, 2), padding=\"same\" \n",
    "                        , activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.Conv2D(512, (4, 4), strides=(2, 2), padding=\"same\" ,\n",
    "                        activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.Conv2D(1024, (3, 3), strides=(2, 2), padding=\"same\", \n",
    "                         activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.GlobalMaxPooling2D(),\n",
    "          layers.Dense(1, activation='sigmoid')\n",
    "      ],\n",
    "      name=\"discriminator\",\n",
    "  )\n",
    "  return discriminator\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "  generator = keras.Sequential(\n",
    "      [\n",
    "          keras.layers.InputLayer((generator_input,)),\n",
    "          layers.Reshape((image_size, image_size, num_classes)),\n",
    "          layers.Conv2DTranspose(2048, (7,7), strides=(1, 1), padding=\"same\", activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.Conv2DTranspose(1024, (7, 7), strides=(1, 1), padding=\"same\", activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.Conv2DTranspose(512, (7, 7), strides=(1, 1), padding=\"same\", activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.Conv2DTranspose(256, (7, 7), strides=(1, 1), padding=\"same\", activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.BatchNormalization(momentum=0.5),\n",
    "          layers.LeakyReLU(alpha=0.2),      \n",
    "          layers.Conv2DTranspose(128, (7, 7), strides=(1, 1), padding=\"same\", activity_regularizer=keras.regularizers.L2(.00001)),\n",
    "          layers.LeakyReLU(alpha=0.2),\n",
    "          layers.Conv2DTranspose(1, (7, 7), strides=(1, 1), padding=\"same\", activation='tanh'),\n",
    "          layers.LeakyReLU(alpha=0.2)\n",
    "      ],\n",
    "      name=\"generator\",\n",
    "  )\n",
    "  return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lQmPkPlhISfz"
   },
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        #load data\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dimension for the labels\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Generate random points in the latent space.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        #Add the labels\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "        #Generate fake terrain with generator\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        #Combine terrain with labels\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        #Real and Fake Terrain\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        #Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        #Track loss\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "\n",
    "        return{\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ye2CfRcWQqy3"
   },
   "outputs": [],
   "source": [
    "class Custom_Callback(keras.callbacks.Callback):\n",
    "   def on_epoch_end(self, epoch, logs=None):\n",
    "   #Saves Generator and Discriminator every 20 epochs\n",
    "         if (epoch%20 == 0) and (epoch != 0):\n",
    "           cond_gan.generator.save(path_for_folder_to_save_models + '/generator_' + str(epoch))\n",
    "           cond_gan.discriminator.save(path_for_folder_to_save_models + '/discriminator_' + str(epoch))\n",
    "       #If discriminator loss is very close to zero training stops  \n",
    "         if logs.get('d_loss') < .0001:\n",
    "           self.model.stop_training = True\n",
    "custom_checkpoint = Custom_Callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7EGhwZBFrjHw"
   },
   "outputs": [],
   "source": [
    "#Learning rate decays at rate initial_learning_rate * .9986^(decay_steps/steps_per_epoch)\n",
    "g_initial_learning_rate = 0.001\n",
    "d_initial_learning_rate = 0.001\n",
    "g_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    g_initial_learning_rate,\n",
    "    decay_steps=steps_per_epoch,\n",
    "    decay_rate=.9986)\n",
    "d_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    d_initial_learning_rate,\n",
    "    decay_steps=steps_per_epoch,\n",
    "    decay_rate=.9986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FPPDUfDtIg35"
   },
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=d_lr_schedule),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=g_lr_schedule),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xnk0FyVWqE1o",
    "outputId": "36299455-6efe-4106-b2c0-93c723d07484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fc848aca7981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcond_gan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcustom_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,2048,1000,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node generator/conv2d_transpose/conv2d_transpose_1\n (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:5532)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4834]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node generator/conv2d_transpose/conv2d_transpose_1:\nIn[0] generator/conv2d_transpose/stack_1 (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py:1333)\t\nIn[1] generator/conv2d_transpose/conv2d_transpose_1/ReadVariableOp:\t\nIn[2] generator/reshape/Reshape_1 (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/core/reshape.py:126)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n>>>     self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-17-fc848aca7981>\", line 1, in <module>\n>>>     cond_gan.fit(dataset, epochs=700, callbacks=[custom_checkpoint])\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"<ipython-input-13-0427ea5fb352>\", line 75, in train_step\n>>>     fake_images = self.generator(random_vector_labels)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 1341, in call\n>>>     dilation_rate=self.dilation_rate)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5532, in conv2d_transpose\n>>>     data_format=tf_data_format)\n>>> "
     ]
    }
   ],
   "source": [
    "cond_gan.fit(dataset, epochs=700, callbacks=[custom_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ai8w03pSOYND"
   },
   "outputs": [],
   "source": [
    "cond_gan.generator.save(path_for_folder_to_save_models + \"/generator_final\")\n",
    "cond_gan.discriminator.save(path_for_folder_to_save_models + \"/discriminator_final\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CGAN_1000_by_1000.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
